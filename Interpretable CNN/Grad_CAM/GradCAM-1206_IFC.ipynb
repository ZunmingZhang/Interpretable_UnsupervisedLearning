{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "from pytorch_grad_cam import GradCAM,ScoreCAM,GradCAMPlusPlus,AblationCAM,XGradCAM,EigenCAM,EigenGradCAM,LayerCAM,FullGrad,GradCAMElementWise\n",
    "from pytorch_grad_cam import GuidedBackpropReLUModel\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image,deprocess_image,preprocess_image,preprocess_grayimage\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os,sys\n",
    "import copy\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from scipy.io import savemat\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import shutil\n",
    "import math\n",
    "import fnmatch\n",
    "import nets\n",
    "from collections import OrderedDict\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score\n",
    "import seaborn as sns\n",
    "from pytorch_model_summary import summary\n",
    "from torch.nn.utils import weight_norm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAE_2d_classify(nn.Module):\n",
    "    def __init__(self, input_shape=[400,400,1], latent_channels=512, num_clusters=2, filters=[32, 64, 128, 256], dropout=0.1):\n",
    "        super(CAE_2d_classify, self).__init__()\n",
    "        self.pretrained = False\n",
    "        self.latent_channels = latent_channels\n",
    "        self.input_shape = input_shape\n",
    "        self.filters = filters\n",
    "        self.num_clusters = num_clusters\n",
    "        \n",
    "        self.encoder2d = nn.Sequential(OrderedDict([\n",
    "            ('conv2d1_1', nn.Conv2d(input_shape[2], filters[0], 5, stride=2, padding=2, bias=False)),\n",
    "          ('relu2d1_1', nn.ReLU()),\n",
    "          ('bn2d1_1', nn.BatchNorm2d(filters[0])),\n",
    "            ('conv2d2_1', nn.Conv2d(filters[0], filters[1], 5, stride=2, padding=2, bias=False)),\n",
    "          ('relu2d2_1', nn.ReLU()),\n",
    "          ('bn2d2_1', nn.BatchNorm2d(filters[1])),\n",
    "            ('conv2d3_1', nn.Conv2d(filters[1], filters[2], 5, stride=2, padding=2, bias=False)),\n",
    "          ('relu2d3_1', nn.ReLU()),\n",
    "          ('bn2d3_1', nn.BatchNorm2d(filters[2])),\n",
    "            ('conv2d4_1', nn.Conv2d(filters[2], filters[3], 3, stride=2, padding=0, bias=False)),\n",
    "          ('relu2d4_1', nn.ReLU()),\n",
    "        ]))\n",
    "        lin_features_len = ((input_shape[0] // 2 // 2 // 2 - 1) // 2) * ((input_shape[1] // 2 // 2 // 2 - 1) // 2) * \\\n",
    "                           filters[3]\n",
    "        self.embedding2d = nn.Linear(lin_features_len, latent_channels, bias=False)\n",
    "        self.fc1 = nn.Linear(latent_channels, 1024)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(1024)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(1024, num_clusters)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # tansmission\n",
    "        x = self.encoder2d(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.embedding2d(x)\n",
    "        x_out = x\n",
    "        \n",
    "        x = x\n",
    "        x = self.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn_fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        pred = nn.functional.log_softmax(x,dim=1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import skimage.transform\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class MyDataset_mat(Dataset):\n",
    "    def __init__(self, tm_paths, labels, transforms_tm=None, transforms_fl=None):\n",
    "        self.paths_tm = tm_paths\n",
    "        self.transforms_tm = transforms_tm\n",
    "        self.transforms_fl = transforms_fl\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index, load_fl=False):\n",
    "        data_tm = sio.loadmat(self.paths_tm[index])['data']\n",
    "#         data_tm = np.transpose(np.array(cv2.cvtColor(data_tm,cv2.COLOR_GRAY2RGB)), (2,0,1))\n",
    "        \n",
    "        x_tm = torch.from_numpy(data_tm.astype(np.float32)/65535)\n",
    "        x_tm = x_tm.unsqueeze(dim = 0)\n",
    "        \n",
    "        label = torch.from_numpy(np.asarray(self.labels[index]))\n",
    "        label = label.to(torch.int64)\n",
    "        if self.transforms_tm:\n",
    "            x_tm = self.transforms_tm(x_tm)\n",
    "        if load_fl:\n",
    "            name = self.paths_tm[index]\n",
    "            fldir = name[:-23]\n",
    "            base_name = name[-19:-10]\n",
    "            flname = fldir+'FL/'+base_name+'_2DFL.mat'\n",
    "            data_fl = sio.loadmat(flname)['data']\n",
    "            x_fl = torch.from_numpy(data_fl.astype(np.float32)/65535)\n",
    "            x_fl = x_fl.unsqueeze(dim = 0)\n",
    "            if self.transforms_fl:\n",
    "                x_fl = self.transforms_fl(x_fl)\n",
    "        if load_fl:\n",
    "            return x_tm, x_fl, label\n",
    "        else:\n",
    "            return x_tm, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths_tm)\n",
    "    \n",
    "#Visualize image stacks\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "def DisplayImage(img,LimMin,LimMax,title='2D Projection'):  \n",
    "    if img.shape[2]>1:\n",
    "        for depth in range (0,10):\n",
    "            plt.subplot(2,5,depth+1)\n",
    "            plt.imshow(img[:,:,depth*8],vmin=LimMin, vmax=LimMax, cmap ='jet')\n",
    "            # plt.colorbar()\n",
    "            plt.title('z = '+ str(depth))\n",
    "            if depth==9:\n",
    "                plt.subplot(2,5,depth+1)\n",
    "                plt.title('z = '+ str(depth))\n",
    "                ax = plt.gca()\n",
    "                fig4 = plt.imshow(img[:,:,depth*8],vmin=LimMin, vmax=LimMax, cmap ='jet')\n",
    "\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        plt.colorbar(fig4, cax=cax)\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig4 = plt.imshow(np.squeeze(img),vmin=LimMin, vmax=LimMax, cmap ='gray')\n",
    "        plt.title(title)\n",
    "        ax = plt.gca()\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        plt.colorbar(fig4, cax=cax)\n",
    "        plt.show()\n",
    "def DisplayandSaveImage(img,LimMin,LimMax,title='2D Projection',save_name='2D Projection.jpg'):  \n",
    "    if img.shape[2]>1:\n",
    "        for depth in range (0,10):\n",
    "            plt.subplot(2,5,depth+1)\n",
    "            plt.imshow(img[:,:,depth*8],vmin=LimMin, vmax=LimMax, cmap ='jet')\n",
    "            # plt.colorbar()\n",
    "            plt.title('z = '+ str(depth))\n",
    "            if depth==9:\n",
    "                plt.subplot(2,5,depth+1)\n",
    "                plt.title('z = '+ str(depth))\n",
    "                ax = plt.gca()\n",
    "                fig4 = plt.imshow(img[:,:,depth*8],vmin=LimMin, vmax=LimMax, cmap ='jet')\n",
    "\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        plt.colorbar(fig4, cax=cax)\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig4 = plt.imshow(np.squeeze(img),vmin=LimMin, vmax=LimMax, cmap ='gray')\n",
    "        plt.title(title)\n",
    "        ax = plt.gca()\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        plt.colorbar(fig4, cax=cax)\n",
    "        plt.savefig(save_name, dpi=200)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1999c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = './reports/PT_GroundTruthLabel&ClusterLabel.csv'\n",
    "csv_data = pd.read_csv(csv_path)\n",
    "\n",
    "sscpath = csv_data.name\n",
    "tmpath = csv_data.tmname\n",
    "cluster_label = csv_data.cluster\n",
    "truth_label = csv_data.label\n",
    "print(cluster_label[0])\n",
    "print('Type of label: ', type(cluster_label[0]))\n",
    "    \n",
    "transforms_tm = transforms.Resize([400, 400])\n",
    "total_datasets = MyDataset_mat(tmpath, cluster_label, transforms_tm=transforms_tm)\n",
    "print('Total data size: ', len(total_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0768cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--use-cuda', action='store_true', default=True,\n",
    "                        help='Use NVIDIA GPU acceleration')\n",
    "    parser.add_argument(\n",
    "        '--image-path',\n",
    "        type=str,\n",
    "        default='./examples/both.png',\n",
    "        help='Input image path')\n",
    "    parser.add_argument('--aug_smooth', action='store_true', default=False,\n",
    "                        help='Apply test time augmentation to smooth the CAM')\n",
    "    parser.add_argument('--eigen_smooth', action='store_true', default=False,\n",
    "        help='Reduce noise by taking the first principle componenet of cam_weights*activations')\n",
    "    parser.add_argument('--method', type=str, default='ablationcam',\n",
    "                        choices=['gradcam', 'gradcam++', 'scorecam', 'xgradcam', 'ablationcam', 'eigencam', 'eigengradcam', 'layercam', 'fullgrad'],\n",
    "                        help='Can be gradcam/gradcam++/scorecam/xgradcam/ablationcam/eigencam/eigengradcam/layercam')\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    args.use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "    if args.use_cuda:\n",
    "        print('Using GPU for acceleration')\n",
    "    else:\n",
    "        print('Using CPU for computation')\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Display_cam(input_img, cam_img, cam_mask, fl_mask, save_name=None):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(input_img,vmin=input_img.min(), vmax=input_img.max(), cmap ='gray')\n",
    "    plt.title('Input Image')\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(cam_img,vmin=cam_img.min(), vmax=cam_img.max(), cmap ='gray')\n",
    "    plt.title('CAM Image')\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(cam_mask,vmin=cam_mask.min(), vmax=cam_mask.max(), cmap ='gray')\n",
    "    plt.title('CAM Mask')\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(fl_mask,vmin=fl_mask.min(), vmax=fl_mask.max(), cmap ='gray')\n",
    "    plt.title('FL Mask')\n",
    "    if save_name is not None:\n",
    "        plt.savefig(save_name, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be75b970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "args.method = 'gradcam'\n",
    "methods = {\"gradcam\": GradCAM,\n",
    "     \"scorecam\": ScoreCAM,\n",
    "     \"gradcam++\": GradCAMPlusPlus,\n",
    "     \"ablationcam\": AblationCAM,\n",
    "     \"xgradcam\": XGradCAM,\n",
    "     \"eigencam\": EigenCAM,\n",
    "     \"eigengradcam\": EigenGradCAM,\n",
    "     \"layercam\": LayerCAM,\n",
    "     \"fullgrad\": FullGrad,\n",
    "     \"gradcamelementwise\": GradCAMElementWise}\n",
    "\n",
    "basedir = 'nets/ckpt_CAE_2d_classify_001/'\n",
    "scratch_model = torch.load(basedir+'Classify_Trained_001_latest.pth.tar')\n",
    "img_size = [400, 400, 1]\n",
    "latent_channels = 512\n",
    "model_name = 'CAE_2d_classify'\n",
    "CellName = ['Translocated', 'Un-Translocated']\n",
    "threshold_cam = 0.15\n",
    "threshold_fl = 0.3\n",
    "\n",
    "for ii in range(len(total_datasets)):\n",
    "# for ii in range(2):\n",
    "    to_eval = model_name + \"()\"\n",
    "    model = eval(to_eval)\n",
    "    model.load_state_dict(scratch_model['best_model_wts'])\n",
    "    target_layers = [model.encoder2d.conv2d4_1]\n",
    "    \n",
    "    [ImgTensor,FLTensor, ImgLabel] = total_datasets.__getitem__(ii, load_fl=True)\n",
    "\n",
    "    rgb_img = np.squeeze(np.float32(ImgTensor))\n",
    "    input_tensor = ImgTensor.unsqueeze(0)\n",
    "\n",
    "\n",
    "    # We have to specify the target we want to generate\n",
    "    # the Class Activation Maps for.\n",
    "    # If targets is None, the highest scoring category (for every member in the batch) will be used.\n",
    "    # You can target specific categories by\n",
    "    # targets = [e.g ClassifierOutputTarget(281)]\n",
    "    targets = None\n",
    "\n",
    "    # Using the with statement ensures the context is freed, and you can\n",
    "    # recreate different CAM objects in a loop.\n",
    "    cam_algorithm = methods[args.method]\n",
    "    with cam_algorithm(model=model,\n",
    "                       target_layers=target_layers,\n",
    "                       use_cuda=args.use_cuda) as cam:\n",
    "\n",
    "        # AblationCAM and ScoreCAM have batched implementations.\n",
    "        # You can override the internal batch size for faster computation.\n",
    "        cam.batch_size = 32\n",
    "        grayscale_cam = cam(input_tensor=input_tensor,\n",
    "                            targets=targets,\n",
    "                            aug_smooth=args.aug_smooth,\n",
    "                            eigen_smooth=args.eigen_smooth)\n",
    "\n",
    "        # Here grayscale_cam has only one image in the batch\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=False)\n",
    "\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, use_cuda=args.use_cuda)\n",
    "    gb = gb_model(input_tensor, target_category=ImgLabel)\n",
    "\n",
    "    cam_mask = grayscale_cam\n",
    "    cam_gb = cam_mask * np.squeeze(gb)\n",
    "    cam_mask_thresholded = cam_mask.copy()\n",
    "    cam_mask_thresholded[cam_mask_thresholded<threshold_cam*cam_mask.max()]=0\n",
    "    cam_mask_thresholded[cam_mask_thresholded>=threshold_cam*cam_mask.max()]=1\n",
    "    \n",
    "    fl_img = FLTensor.numpy()\n",
    "    fl_img_thresholded = fl_img\n",
    "    fl_img_thresholded[fl_img_thresholded<threshold_fl*fl_img.max()]=0\n",
    "    fl_img_thresholded[fl_img_thresholded>=threshold_fl*fl_img.max()]=1\n",
    "\n",
    "    \n",
    "    input_img = np.transpose(np.expand_dims(np.squeeze(ImgTensor.numpy()), axis=0), (1,2,0))\n",
    "    cam_mask_thresholded = np.transpose(np.expand_dims(np.squeeze(cam_mask_thresholded), axis=0), (1,2,0))\n",
    "    fl_mask_thresholded = np.transpose(np.expand_dims(np.squeeze(fl_img_thresholded), axis=0), (1,2,0))\n",
    "    cam_img = np.transpose(np.expand_dims(np.squeeze(cam_mask), axis=0), (1,2,0))\n",
    "    \n",
    "    Display_cam(input_img, cam_img, cam_mask_thresholded, fl_mask_thresholded, save_name=f'Images_Resize/{CellName[ImgLabel]}/{ii}_{args.method}.jpg')\n",
    "    \n",
    "    name = tmpath[ii]\n",
    "    base_dir = name[:-23]\n",
    "    base_name = name[-19:-10]\n",
    "    maskname = base_dir+'Mask/'+base_name+'_2DMask.mat'\n",
    "\n",
    "    maskdata = {'data':cam_mask_thresholded}\n",
    "    savemat(maskname, maskdata)\n",
    "    print('\\nCluster label:', CellName[cluster_label[ii]])\n",
    "    print('Ground Truth label:', CellName[truth_label[ii]])\n",
    "    if ii == 0:\n",
    "        name_ssc = [sscpath[ii]]\n",
    "        name_tm = [tmpath[ii]]\n",
    "        name_mask = [maskname]\n",
    "        label_cluster = [cluster_label[ii]]\n",
    "        label_truth = [truth_label[ii]]\n",
    "    else:\n",
    "        name_ssc = np.append(name_ssc, [sscpath[ii]], axis=0)\n",
    "        name_tm = np.append(name_tm, [tmpath[ii]], axis=0)\n",
    "        name_mask = np.append(name_mask, [maskname], axis=0)\n",
    "        label_cluster = np.append(label_cluster, [cluster_label[ii]], axis=0)\n",
    "        label_truth = np.append(label_truth, [truth_label[ii]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e901762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "my_dict = {'name': name_ssc, 'tmname': name_tm, 'maskname': name_mask, 'label': label_truth, 'cluster': label_cluster}\n",
    "headers = my_dict.keys()\n",
    "with open('./reports/PT_mask.csv', 'w', newline='') as f:  # You will need 'wb' mode in Python 2.x\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(headers)\n",
    "    writer.writerows(zip(*my_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364ba08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
